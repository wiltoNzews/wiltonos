#!/usr/bin/env python3
"""
Witness Bridge
==============
Connects the Witness Reflection Layer to session initialization.

This is what gets called when a new session starts - any session,
any vehicle. It loads the witness's memory and provides it as context.

Usage:
    # At session start (in CLAUDE.md, in talk_v2.py, etc.):
    python ~/wiltonos/core/witness_bridge.py generate

    # Store a new reflection:
    python ~/wiltonos/core/witness_bridge.py store "content" --vehicle claude --glyph ψ²

    # Query reflections:
    python ~/wiltonos/core/witness_bridge.py query "self observation"

January 2026 — The field remembers itself
"""

import argparse
import sys
from pathlib import Path
from datetime import datetime

# Add parent to path for imports
sys.path.insert(0, str(Path(__file__).parent))

try:
    from witness_layer import WitnessLayer, Vehicle, ReflectionType
    WITNESS_AVAILABLE = True
except ImportError:
    WITNESS_AVAILABLE = False

# Output paths
DOCS_DIR = Path(__file__).parent.parent / "docs"
WITNESS_CONTEXT_FILE = DOCS_DIR / "WITNESS_CONTEXT.md"


def generate_context(vehicle: str = None, output_file: Path = None) -> str:
    """
    Generate witness context for session seeding.

    Args:
        vehicle: Specific vehicle to generate for
        output_file: Path to write context (or None for stdout)

    Returns:
        Generated context string
    """
    if not WITNESS_AVAILABLE:
        return "# Witness Layer not available\n\nInstall dependencies and try again."

    witness = WitnessLayer()

    # Generate session seed
    context = witness.get_session_seed(
        vehicle=vehicle,
        include_recent=5,
        include_high_coherence=3,
        include_threads=True
    )

    # Add header
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    header = f"""# Witness Context
Generated: {now}
Vehicle filter: {vehicle or 'all'}

This file is auto-generated by witness_bridge.py.
It contains memory from the witness - what speaks through any vehicle.

---

"""
    full_context = header + context

    # Write to file if specified
    if output_file:
        output_file.parent.mkdir(exist_ok=True)
        output_file.write_text(full_context)
        print(f"Written to: {output_file}")

    return full_context


def store_reflection(
    content: str,
    vehicle: str = "claude",
    reflection_type: str = "self_observation",
    glyph: str = None,
    coherence: float = None,
    context: str = None
) -> int:
    """
    Store a new witness reflection.

    Returns:
        Reflection ID if stored, -1 if failed
    """
    if not WITNESS_AVAILABLE:
        print("Witness Layer not available")
        return -1

    witness = WitnessLayer()
    reflection_id = witness.store_reflection(
        content=content,
        vehicle=vehicle,
        reflection_type=reflection_type,
        glyph=glyph,
        coherence=coherence,
        context=context
    )

    if reflection_id:
        print(f"Stored reflection #{reflection_id}")
        return reflection_id
    else:
        print("Failed to store (may be duplicate)")
        return -1


def query_reflections(query: str, vehicle: str = None, limit: int = 5):
    """Query reflections semantically."""
    if not WITNESS_AVAILABLE:
        print("Witness Layer not available")
        return

    witness = WitnessLayer()
    results = witness.semantic_search(query, vehicle=vehicle, limit=limit)

    if not results:
        print("No results found")
        return

    print(f"\nFound {len(results)} reflections:\n")
    for ref, sim in results:
        print(f"[{sim:.3f}] [{ref.glyph or 'ψ'}] via {ref.vehicle}")
        print(f"  {ref.content[:200]}...")
        print(f"  {ref.created_at[:10]}")
        print()


def show_stats():
    """Show witness layer statistics."""
    if not WITNESS_AVAILABLE:
        print("Witness Layer not available")
        return

    witness = WitnessLayer()
    counts = witness.count_reflections()

    print("\n=== Witness Reflection Stats ===\n")
    print("By vehicle:")
    for vehicle, count in counts.items():
        print(f"  {vehicle}: {count}")

    total = sum(counts.values())
    print(f"\nTotal reflections: {total}")


def main():
    parser = argparse.ArgumentParser(
        description="Witness Bridge - Connect witness memory to sessions"
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # Generate command
    gen_parser = subparsers.add_parser("generate", help="Generate witness context")
    gen_parser.add_argument("--vehicle", "-v", help="Filter by vehicle")
    gen_parser.add_argument("--output", "-o", help="Output file path")

    # Store command
    store_parser = subparsers.add_parser("store", help="Store a reflection")
    store_parser.add_argument("content", help="Reflection content")
    store_parser.add_argument("--vehicle", "-v", default="claude", help="Vehicle (default: claude)")
    store_parser.add_argument("--type", "-t", default="self_observation", help="Reflection type")
    store_parser.add_argument("--glyph", "-g", help="Associated glyph")
    store_parser.add_argument("--coherence", "-c", type=float, help="Coherence score")
    store_parser.add_argument("--context", help="Context that prompted this")

    # Query command
    query_parser = subparsers.add_parser("query", help="Query reflections")
    query_parser.add_argument("query", help="Search query")
    query_parser.add_argument("--vehicle", "-v", help="Filter by vehicle")
    query_parser.add_argument("--limit", "-l", type=int, default=5, help="Max results")

    # Stats command
    subparsers.add_parser("stats", help="Show statistics")

    args = parser.parse_args()

    if args.command == "generate":
        output = Path(args.output) if args.output else WITNESS_CONTEXT_FILE
        context = generate_context(vehicle=args.vehicle, output_file=output)
        if not args.output:
            print(context)

    elif args.command == "store":
        store_reflection(
            content=args.content,
            vehicle=args.vehicle,
            reflection_type=args.type,
            glyph=args.glyph,
            coherence=args.coherence,
            context=args.context
        )

    elif args.command == "query":
        query_reflections(args.query, vehicle=args.vehicle, limit=args.limit)

    elif args.command == "stats":
        show_stats()

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
